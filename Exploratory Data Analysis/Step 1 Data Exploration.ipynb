{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f024ea22",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for Korean Emotion Multimodal Database in 2020 (KEMDy20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc57392",
   "metadata": {},
   "source": [
    "### Data Information\n",
    "\n",
    "- KEMDy20 is a multimodal emotion dataset:\n",
    "    - speech data\n",
    "    - Text data transcribed from the speech\n",
    "    - electrodermal activity (EDA),\n",
    "    - Inter-Beat-Interval (IBI),\n",
    "    - Wrist skin temperature "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e4f44a",
   "metadata": {},
   "source": [
    "### Data Characteristics\n",
    "\n",
    "| Characteristics  |  Description |  \n",
    "|---|---| \n",
    "|Number of Participants | 80   |  \n",
    "|Age of participants| 19-30  |  \n",
    "| Language  | Korean  |  \n",
    "| Device  | Empatica E4  |  \n",
    "| Stimulus  |  6 videos (~5-minute length) + conversation   |  \n",
    "| Annotation  |  10 External annotators (??)\n",
    "| Labels  | 7 Emotions(“angry”, “sad”, “happy”, “disgust”, “fear”, “surprise”, “neutral”))\n",
    "Arousal & Valence (1-5 scale)  |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3e87ff",
   "metadata": {},
   "source": [
    "### Initial Observation\n",
    "\n",
    "- Data was collected during conversation\n",
    "- The videos watched before the conversation can be considered the stimulus videos, although the conversation is the primary stimulus as the emotions may depend on the emotions of another person in the conversation.\n",
    "- The video was labeled by external annotators. Therefore, this dataset does not deal with the emotions experienced by the participants. As we deal with the observed emotions, the contribution of bio-signal modality may not be crucial.\n",
    "- Annotations were aggregated based solely on majority vote of the external annotators, this may bring ambiguity if there is conflict on opinions of external annotators and highly contrasting emotion labels are assigned to a sample.\n",
    "- Video was recorded during the conversation. \n",
    "- The external annotators **tagged the speech segments while listening to the recorded utternaces** - It is not clear whether the evaluators had access to the facial expressions of the participants. If annotators watched the videos, this could lead to  bias due to lack of facial information in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecbb7c4",
   "metadata": {},
   "source": [
    "### EDA for Bio-signal Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b952e",
   "metadata": {},
   "source": [
    "### Questions to be explored\n",
    "- Is the data ready for ML/DL based analysis or some data cleansing is needed?\n",
    "- What is the size of the data, is there any data excluded/missing?\n",
    "- What is the distribution of different labels. Are there any outliers?\n",
    "- Is there any special consideration needed before building a classification/prediction model?\n",
    "\n",
    "##### Answers:\n",
    "- The dataset is well organized in the folders for different modalitie. However, the number of samples in the modalities do not match. (ie. there are missing samples in some modalities)\n",
    "- This discrepency in number of samples may arise due to various reasons including faulty data due to device malfunction, participant's decision to opt-out etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc75a69",
   "metadata": {},
   "source": [
    "# Data organization\n",
    "\n",
    "- Each Modality data is organized into 40 folders each representing a session\n",
    "- Each session folder contains data related to 6 conversations between two participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dccaa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataprep.eda import plot_missing, plot, plot_correlation\n",
    "import warnings\n",
    "import shutil\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5393230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"F:/sudarshan/ABAW/ETRI\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f350536b",
   "metadata": {},
   "source": [
    "## Check Annotations\n",
    "\n",
    "- Annotations are organized in CSV files for each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7bb3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotaiton_file = pd.read_csv(f\"{DATA_DIR}/annotation/Sess01_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d004e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any column as missing data\n",
    "isNull =  False\n",
    "for i in range(len(annotaiton_file.columns)): \n",
    "    isNull = pd.isnull(annotaiton_file).any()[i]\n",
    "print(isNull)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotaiton_file.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6014491",
   "metadata": {},
   "source": [
    "### Observations\n",
    "- The annotation file contains:\n",
    "    - the annotation by all 10 evaluators\n",
    "    - total evaluation (Average)\n",
    "    - Segment times for WAV file (NOT SURE if this is relevant:: WAV files are already split into corresponding segments)\n",
    "    - labels for both emotion and arousal/valence are provided\n",
    "    \n",
    "- We are interested in labels for overall valence and arousal  (Total Evaluation), we we can discard other columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709555e5",
   "metadata": {},
   "source": [
    "### Select required columns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f1500",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotaiton_data_ = annotaiton_file.iloc[1:, [3,4,5,6]]\n",
    "annotaiton_data_.columns = [\"segment_id\", 'emotion', 'arousal', 'valence']\n",
    "annotaiton_data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d0dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotaiton_data_['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup the dataframe to include only the columns required for training\n",
    "def prepare_cleaned_dataframe(session_num):\n",
    "    annot_df = pd.read_csv(f\"{DATA_DIR}/annotation/Sess{session_num:02}_eval.csv\") \n",
    "    annot_df = annot_df.iloc[1:, [3,4,5,6]]\n",
    "    annot_df.columns = [\"segment_id\", 'emotion', 'arousal', 'valence'] \n",
    "    return annot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20901d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame()\n",
    "for session_num in range(1, 41): \n",
    "    full_df = full_df.append(prepare_cleaned_dataframe(session_num), ignore_index=True)\n",
    "print(full_df.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa5ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13291e4",
   "metadata": {},
   "source": [
    "#### Some samples were found to have multiple emotion labels.\n",
    "\n",
    "In this case, we can select the labels with least occurence to avoid class imbalance to some extent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb130c9",
   "metadata": {},
   "source": [
    "## Fix labels using the labels with least occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd12f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_map = {\"happy;neutral\": \"happy\", \n",
    "              \"angry;neutral\": \"angry\",\n",
    "               \"neutral;sad\": \"sad\",\n",
    "               \"surprise;neutral\": \"surprise\",\n",
    "               \"neutral;disqust\": \"disgust\",\n",
    "               \"neutral;fear\": \"fear\",\n",
    "               \"happy;surprise\": \"surprise\",\n",
    "               \"angry;disqust\": \"angry\",\n",
    "               \"happy;fear\": \"fear\",\n",
    "               \"angry;neutral;disqust\": \"disgust\",\n",
    "               \"neutral;disqust;sad\": \"disgust\",\n",
    "               \"angry;neutral;disqust;fear;sad\": \"fear\",\n",
    "               \"happy;sad\": \"sad\",\n",
    "               \"happy;surprise;neutral\": \"surprise\",\n",
    "               \"happy;angry;neutral\": \"angry\",\n",
    "               \"happy;neutral;disqust\": \"disgust\",\n",
    "               \"happy;neutral;fear\": \"fear\", \n",
    "               \"disqust\": \"disgust\"\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['emotion'] = full_df['emotion'].replace(replace_map)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf3dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c171cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a61367",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(\"labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d738e9ea",
   "metadata": {},
   "source": [
    "# Electrodermal Activity(EDA)\n",
    "- EDA Data is organized in folders of 40 sessions\n",
    "- Each session has data from 6 paired conversations ie. 12 recordings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccc2771",
   "metadata": {},
   "source": [
    "####  It should be noted that there are three columns. third column showing which segment the data belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = pd.read_csv(f\"{DATA_DIR}/EDA/Session01/Sess01_script01_User001F.csv\", skiprows=2, header=None, names=[\"eda_value\", \"time_stamp\", \"segment_id\"])\n",
    "print(df_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f06f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda['eda_value'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db697b8",
   "metadata": {},
   "source": [
    "#### select the rows with target segments only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58858e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_segments = df_eda.dropna()\n",
    "print(df_target_segments.shape)\n",
    "df_target_segments.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad58998b",
   "metadata": {},
   "source": [
    "#### As it has different segments let's seperate based on segment Id\n",
    "- The number of segments may vary, so find the unique segmetns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a80bfbc",
   "metadata": {},
   "source": [
    "### Extract all EDA segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5114518",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_ids_annot = full_df['segment_id'].values\n",
    "len(seg_ids_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf5740",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_segments = 0\n",
    "for sess__ in [f'Session{sess:02}' for sess in range(1,41)]: \n",
    "    for eda_file in os.listdir(f\"{DATA_DIR}/EDA/{sess__}\"):\n",
    "        df_eda_ = pd.read_csv(f\"{DATA_DIR}/EDA/{sess__}/{eda_file}\", skiprows=2, header=None, names=[\"eda_value\", \"time_stamp\", \"segment_id\"])\n",
    "        df_target_segments_ = df_eda_.dropna()\n",
    "        groups = df_target_segments_.groupby(\"segment_id\")[\"eda_value\"]\n",
    "        \n",
    "        out_dir_  = f\"{DATA_DIR}/preprocessed/EDA/{sess__}\"\n",
    "        if not os.path.exists(out_dir_):\n",
    "            os.makedirs(out_dir_)\n",
    "        \n",
    "        for x, group_data in enumerate(groups):\n",
    "            if group_data[0] in seg_ids_annot:\n",
    "                group_data[1].to_csv(f\"{out_dir_}/{group_data[0]}.csv\", index=False)\n",
    "                total_segments =  total_segments + 1 \n",
    "            else:\n",
    "                print(f\"{group_data[0]} has no annotation available.\")\n",
    "print(f\"Extracted {total_segments} segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a28135",
   "metadata": {},
   "source": [
    "#### There were 13415 segments in EDA data.  \n",
    "\n",
    "-- But Not all are in annotation file\n",
    "So selected only those present in annotation file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaa9af",
   "metadata": {},
   "source": [
    "# IBI Data\n",
    "\n",
    "IBI data is also organized in a similar way : 40 folders of the segmetns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc937e9",
   "metadata": {},
   "source": [
    "### Extract all IBI segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_segments = 0\n",
    "for sess__ in [f'Session{sess:02}' for sess in range(1,41)]: \n",
    "    for ibi_file in os.listdir(f\"{DATA_DIR}/IBI/{sess__}\"):\n",
    "        df_ibi = pd.read_csv(f\"{DATA_DIR}/IBI/{sess__}/{ibi_file}\", skiprows=1, header=None, names=[\"time_diff\", \"ibi_value\", \"time_stamp\", \"segment_id\"])\n",
    "        df_target_segments_ = df_ibi.dropna()\n",
    "        groups = df_target_segments_.groupby(\"segment_id\")[\"ibi_value\"]\n",
    "        \n",
    "        out_dir_  = f\"{DATA_DIR}/preprocessed/IBI/{sess__}\"\n",
    "        if not os.path.exists(out_dir_):\n",
    "            os.makedirs(out_dir_)\n",
    "        \n",
    "        for x, group_data in enumerate(groups):                \n",
    "            if group_data[0] in seg_ids_annot:\n",
    "                group_data[1].to_csv(f\"{out_dir_}/{group_data[0]}.csv\", index=False)\n",
    "                total_segments =  total_segments + 1 \n",
    "            else:\n",
    "                print(f\"{group_data[0]} has no annotation available.\")\n",
    "print(f\"Extracted {total_segments} segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1ca3ba",
   "metadata": {},
   "source": [
    "#### ONLY 10204  segments were found. MAYBE SOME DATA IS MISSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c974853",
   "metadata": {},
   "source": [
    "# Temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40611f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_segments = 0\n",
    "for sess__ in [f'Session{sess:02}' for sess in range(1,41)]: \n",
    "    for temp_file in os.listdir(f\"{DATA_DIR}/TEMP/{sess__}\"):\n",
    "        df_temp = pd.read_csv(f\"{DATA_DIR}/TEMP/{sess__}/{temp_file}\", skiprows=2, header=None, names=[\"temp_value\", \"time_stamp\", \"segment_id\"])\n",
    "        df_target_segments_ = df_temp.dropna()\n",
    "        groups = df_target_segments_.groupby(\"segment_id\")[\"temp_value\"]\n",
    "        \n",
    "        out_dir_  = f\"{DATA_DIR}/preprocessed/TEMP/{sess__}\"\n",
    "        if not os.path.exists(out_dir_):\n",
    "            os.makedirs(out_dir_)\n",
    "        \n",
    "        for x, group_data in enumerate(groups):                \n",
    "            if group_data[0] in seg_ids_annot:\n",
    "                group_data[1].to_csv(f\"{out_dir_}/{group_data[0]}.csv\", index=False)\n",
    "                total_segments =  total_segments + 1 \n",
    "            else:\n",
    "                print(f\"{group_data[0]} has no annotation available.\")\n",
    "print(f\"Extracted {total_segments} segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803fb35",
   "metadata": {},
   "source": [
    "# Audio & Text \n",
    "\n",
    "- The dataset also contains the audio recordings and the transcripts of the conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAV_DIR = \"F:/sudarshan/ABAW/ETRI/wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for sess__ in [f'Session{sess:02}' for sess in range(1,41)]: \n",
    "    files.extend(os.listdir(f\"{WAV_DIR}/{sess__}\"))\n",
    "\n",
    "print(len(files)/2)\n",
    "count_valid = 0;\n",
    "for file____ in files:\n",
    "    if \".txt\" in file____:\n",
    "        if file____[:-4] in valid_segment_ids:\n",
    "            count_valid = count_valid + 1 \n",
    "        else:\n",
    "            print(file____)\n",
    "print(count_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac68fcb",
   "metadata": {},
   "source": [
    "### We have 13462 samples with both audio and text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64085016",
   "metadata": {},
   "source": [
    "# As WAV and Txt modalities are complete. Check how many samples missing based on these\n",
    "### first, take all the segments from audio as audio and text have all matching files available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635213d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAV files\n",
    "WAV_DIR = \"F:/sudarshan/ABAW/ETRI/wav\"\n",
    "files = []\n",
    "for sess__ in [f'Session{sess:02}' for sess in range(1,41)]: \n",
    "    files.extend(os.listdir(f\"{WAV_DIR}/{sess__}\"))\n",
    "segment_ids = [f_[:-4] for f_ in files if '.wav' in f_]\n",
    "print(len(segment_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a8bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotated samples\n",
    "seg_ids_annot = full_df['segment_id'].values\n",
    "len(seg_ids_annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83285a7b",
   "metadata": {},
   "source": [
    "- This number matches exactly with the annotation samples\n",
    "- Now lets check EDA and TEMP samples (We ignored IBI as there are only a few samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa62687",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"F:/sudarshan/ABAW/ETRI/preprocessed\"\n",
    "files_EDA = []\n",
    "files_TEMP = []\n",
    "count  = 0\n",
    "for sess__ in [f'Session{sess:02}' for sess in range(1,41)]: \n",
    "    files_EDA.extend(os.listdir(f\"{data_dir}/EDA/{sess__}\"))\n",
    "    files_TEMP.extend(os.listdir(f\"{data_dir}/TEMP/{sess__}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90175a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"EDA: {len(files_EDA)}, TEMP: {len(files_TEMP)}, Annotations: {len(seg_ids_annot)}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e71367",
   "metadata": {},
   "source": [
    "### Find the missing ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91599ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "13462-12715 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7554aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_in_eda = []\n",
    "for segment_id_ in seg_ids_annot:\n",
    "    if segment_id_+\".csv\" not in files_EDA:\n",
    "        missing_in_eda.append(segment_id_)\n",
    "len(missing_in_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8842e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_in_temp = []\n",
    "for segment_id_ in seg_ids_annot:\n",
    "    if segment_id_+\".csv\" not in files_TEMP:\n",
    "        missing_in_temp.append(segment_id_)\n",
    "len(missing_in_temp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a73b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if they are same\n",
    "for eda_miss_ in missing_in_eda:\n",
    "    if eda_miss_ not in missing_in_temp:\n",
    "        print(\"MISSING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f539fb",
   "metadata": {},
   "source": [
    "### get final annotation file based on 12715 samples available in EDA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id_in_eda = [seg_id[:-4] for seg_id in files_EDA] # removed extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430be1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(segment_id_in_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aeda7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d874901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_annot_df = full_df[full_df['segment_id'].isin(segment_id_in_eda)]\n",
    "final_annot_df.to_csv(\"annotation_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4333bbb",
   "metadata": {},
   "source": [
    "##### Now select from text and WAV (If we want to run text-audio bimodal modell later we can use full dataset for multimodal we use 12715 smaples only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sess__ in [f'Session{sess:02}' for sess in range(1,41)]: \n",
    "    for wav_or_txt in os.listdir(f\"{WAV_DIR}/{sess__}\"):\n",
    "        if wav_or_txt[:-4] in segment_id_in_eda: \n",
    "            src_file = f\"{WAV_DIR}/{sess__}/{wav_or_txt}\"\n",
    "            dest_dir = f\"{DATA_DIR}/KEMDy20/WAV\" if \".wav\" in wav_or_txt else f\"{DATA_DIR}/KEMDy20/TXT\"\n",
    "            shutil.copy(src_file, dest_dir)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
