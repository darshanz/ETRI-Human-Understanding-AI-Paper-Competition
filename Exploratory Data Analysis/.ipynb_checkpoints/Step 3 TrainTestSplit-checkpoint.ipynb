{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "122796d0",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f9fa94",
   "metadata": {},
   "source": [
    "## Dataset Split\n",
    "\n",
    "We (randomly) split the dataset into training and testing set at the ratio 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfbba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATASET = \"<PATH TO THE DATASET>/KEMDy20\"\n",
    "DIR_DATASET_ERC = \"<PATH TO THE DATASET>/KEMDy20ERCNew\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split the sessin numbers into train and test\n",
    "def split_train_test_val(): \n",
    "    files = list(range(1, 41)) \n",
    "    train = random.sample(files, 32) \n",
    "    test = [f for f in files if f not in train] \n",
    "    # split further into train and valid (they are already randomized; just slice)\n",
    "    train_sessions  = train[:26]\n",
    "    valid_sessions = train[26:]\n",
    "\n",
    "\n",
    "    print(\"Train:\", train_sessions)\n",
    "    print(\"Val:\", valid_sessions)\n",
    "    print(\"Test:\", test)\n",
    "\n",
    "    train_sess_ = [f\"Sess{train_num:02}\" for train_num in train_sessions]\n",
    "    val_sess_ = [f\"Sess{val_num:02}\" for val_num in valid_sessions]\n",
    "    test_sess_ = [f\"Sess{test_num:02}\" for test_num in test]\n",
    "    return train_sess_, val_sess_, test_sess_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1893000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotations\n",
    "def save_split_annotations(train_sess_, val_sess_, test_sess_):\n",
    "    train_label_df = final_annot_df[final_annot_df['segment_id'].str.startswith(tuple(train_sess_))]\n",
    "    train_label_df.to_csv(\"train_labels.csv\", index=False)\n",
    "    val_label_df = final_annot_df[final_annot_df['segment_id'].str.startswith(tuple(val_sess_))]\n",
    "    val_label_df.to_csv(\"val_labels.csv\", index=False)\n",
    "    test_label_df = final_annot_df[final_annot_df['segment_id'].str.startswith(tuple(test_sess_))]\n",
    "    test_label_df.to_csv(\"test_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19698e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sess_, val_sess_, test_sess_ = split_train_test_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6834dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_split_annotations(train_sess_, val_sess_, test_sess_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b9755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_to_split_folders():\n",
    "    for session_ in os.listdir(f\"{DIR_DATASET}/EDA\"): \n",
    "        if session_.replace(\"ion\",\"\") in train_sess_:\n",
    "            print(\"train\")\n",
    "            shutil.copytree(f\"{DIR_DATASET}/EDA/{session_}\", f\"{DIR_DATASET_ERC}/train/{session_}\")\n",
    "        elif session_.replace(\"ion\",\"\") in val_sess_:\n",
    "            print(\"val\")\n",
    "            shutil.copytree(f\"{DIR_DATASET}/EDA/{session_}\", f\"{DIR_DATASET_ERC}/val/{session_}\")\n",
    "        else:\n",
    "            print(\"Test\")\n",
    "            shutil.copytree(f\"{DIR_DATASET}/EDA/{session_}\", f\"{DIR_DATASET_ERC}/test/{session_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_split_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c1b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df =  pd.read_csv(f\"{DIR_DATASET_ERC}/train_labels.csv\")\n",
    "val_labels_df =  pd.read_csv(f\"{DIR_DATASET_ERC}/val_labels.csv\")\n",
    "test_labels_df =  pd.read_csv(f\"{DIR_DATASET_ERC}/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bff7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segments_ = train_labels_df['segment_id'].values\n",
    "val_segments_ = val_labels_df['segment_id'].values\n",
    "test_segments_ = test_labels_df['segment_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09859be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities  = {\"EDA\", \"TEMP\"}\n",
    "for modality in modalities:\n",
    "    for session_ in os.listdir(f\"{DIR_DATASET}/{modality}\"):\n",
    "        for seg_file_ in tqdm(os.listdir(f\"{DIR_DATASET}/{modality}/{session_}\")):\n",
    "            if seg_file_[:-4] in train_segments_:\n",
    "                conv_dir = f\"{DIR_DATASET_ERC}/train/{seg_file_[:15]}\"\n",
    "                if not os.path.exists(conv_dir):\n",
    "                    os.makedirs(conv_dir)\n",
    "                shutil.copy(f\"{DIR_DATASET}/{modality}/{session_}/{seg_file_}\", f\"{conv_dir}/{modality}_{seg_file_}\")\n",
    "            elif seg_file_[:-4] in val_segments_:\n",
    "                conv_dir = f\"{DIR_DATASET_ERC}/val/{seg_file_[:15]}\"\n",
    "                if not os.path.exists(conv_dir):\n",
    "                    os.makedirs(conv_dir)\n",
    "                shutil.copy(f\"{DIR_DATASET}/{modality}/{session_}/{seg_file_}\",  f\"{conv_dir}/{modality}_{seg_file_}\")\n",
    "            if seg_file_[:-4] in test_segments_:\n",
    "                conv_dir = f\"{DIR_DATASET_ERC}/test/{seg_file_[:15]}\"\n",
    "                if not os.path.exists(conv_dir):\n",
    "                    os.makedirs(conv_dir)\n",
    "                shutil.copy(f\"{DIR_DATASET}/{modality}/{session_}/{seg_file_}\",  f\"{conv_dir}/{modality}_{seg_file_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all audio/text files together instead of sessions, in the previous steps : so run this seperately\n",
    "modalities  = {\"TXT\", \"WAV\"}\n",
    "for modality in modalities:\n",
    "        for seg_file_ in os.listdir(f\"{DIR_DATASET}/{modality}\"):\n",
    "            if seg_file_[:-4] in train_segments_:\n",
    "                conv_dir = f\"{DIR_DATASET_ERC}/train/{seg_file_[:15]}\"\n",
    "                if not os.path.exists(conv_dir):\n",
    "                    os.makedirs(conv_dir)\n",
    "                shutil.copy(f\"{DIR_DATASET}/{modality}/{seg_file_}\", f\"{conv_dir}/{modality}_{seg_file_}\")\n",
    "            elif seg_file_[:-4] in val_segments_:\n",
    "                conv_dir = f\"{DIR_DATASET_ERC}/val/{seg_file_[:15]}\"\n",
    "                if not os.path.exists(conv_dir):\n",
    "                    os.makedirs(conv_dir)\n",
    "                shutil.copy(f\"{DIR_DATASET}/{modality}/{seg_file_}\",  f\"{conv_dir}/{modality}_{seg_file_}\")\n",
    "            if seg_file_[:-4] in test_segments_:\n",
    "                conv_dir = f\"{DIR_DATASET_ERC}/test/{seg_file_[:15]}\"\n",
    "                if not os.path.exists(conv_dir):\n",
    "                    os.makedirs(conv_dir)\n",
    "                shutil.copy(f\"{DIR_DATASET}/{modality}/{seg_file_}\",  f\"{conv_dir}/{modality}_{seg_file_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9624e97",
   "metadata": {},
   "source": [
    "Thus, we have the dataset split and organized into train, val and test folders for further experiments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
